{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento Final - YOLOv11 Pothole Detection\n",
    "\n",
    "Este notebook realiza el entrenamiento final del modelo YOLOv11x-seg usando los mejores hiperparámetros encontrados en la optimización bayesiana.\n",
    "\n",
    "## Hardware: RTX 5090 (32GB VRAM)\n",
    "## Model: YOLOv11x-seg (Instance Segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Configuración de estilo\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar GPU disponible\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM Total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de rutas\n",
    "BASE_DIR = Path('..')\n",
    "CONFIG_DIR = BASE_DIR / 'config'\n",
    "MODELS_DIR = BASE_DIR / 'models'\n",
    "OPTIMIZATION_DIR = MODELS_DIR / 'optimization'\n",
    "\n",
    "# Cargar configuración del dataset\n",
    "DATASET_CONFIG = CONFIG_DIR / 'pothole_dataset.yaml'\n",
    "\n",
    "print(f\"Dataset Config: {DATASET_CONFIG}\")\n",
    "print(f\"Models Directory: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar Mejores Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar mejores hiperparámetros de la optimización bayesiana\n",
    "best_params_file = OPTIMIZATION_DIR / 'best_hyperparameters.json'\n",
    "\n",
    "if best_params_file.exists():\n",
    "    with open(best_params_file, 'r') as f:\n",
    "        optimization_results = json.load(f)\n",
    "    \n",
    "    best_params = optimization_results['best_params']\n",
    "    best_value = optimization_results['best_value']\n",
    "    \n",
    "    print(\"MEJORES HIPERPARÁMETROS CARGADOS:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"mAP50-95 en optimización: {best_value:.4f}\")\n",
    "    print(f\"\\nHiperparámetros:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "else:\n",
    "    print(\"ADVERTENCIA: No se encontró archivo de mejores hiperparámetros.\")\n",
    "    print(\"Usando hiperparámetros por defecto.\")\n",
    "    best_params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de Entrenamiento Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de entrenamiento\n",
    "TRAINING_CONFIG = {\n",
    "    'model': 'yolo11x-seg.pt',  # Modelo más grande para mejor accuracy\n",
    "    'epochs': 300,\n",
    "    'patience': 50,\n",
    "    'device': 0,\n",
    "    'workers': 8,\n",
    "    'project': str(MODELS_DIR / 'final_training'),\n",
    "    'name': 'yolo11x_pothole_final',\n",
    "    'exist_ok': True,\n",
    "    'pretrained': True,\n",
    "    'verbose': True,\n",
    "    'plots': True,\n",
    "    'save': True,\n",
    "    'save_period': 10,  # Guardar checkpoint cada 10 epochs\n",
    "    'val': True,\n",
    "    'resume': False,  # Cambiar a True para continuar entrenamiento\n",
    "    'amp': True,  # Automatic Mixed Precision para mejor uso de VRAM\n",
    "    'fraction': 1.0,  # Usar todo el dataset\n",
    "    'profile': False,\n",
    "    'freeze': None,  # No congelar capas\n",
    "    'multi_scale': False,  # Desactivar multi-scale para mayor velocidad\n",
    "    'overlap_mask': True,  # Permitir overlap en máscaras\n",
    "    'mask_ratio': 4,  # Ratio de downsampling para máscaras\n",
    "    'dropout': 0.0,  # Sin dropout\n",
    "    'val_split': 0.0,  # No usar split automático (ya tenemos valid/)\n",
    "}\n",
    "\n",
    "# Combinar con mejores hiperparámetros\n",
    "training_params = {**TRAINING_CONFIG, **best_params}\n",
    "\n",
    "print(\"\\nCONFIGURACIÓN DE ENTRENAMIENTO FINAL:\")\n",
    "print(\"=\"*80)\n",
    "for key, value in training_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo YOLOv11x-seg\n",
    "print(f\"\\nCargando modelo: {TRAINING_CONFIG['model']}\")\n",
    "model = YOLO(TRAINING_CONFIG['model'])\n",
    "\n",
    "# Mostrar información del modelo\n",
    "print(f\"\\nModelo cargado exitosamente!\")\n",
    "print(f\"Tarea: {model.task}\")\n",
    "print(f\"Modelo: {model.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar Modelo\n",
    "\n",
    "Este proceso puede tomar varias horas dependiendo del tamaño del dataset y la configuración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar entrenamiento\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INICIANDO ENTRENAMIENTO FINAL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Inicio: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\nEsto puede tomar varias horas...\\n\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Entrenar\n",
    "results = model.train(\n",
    "    data=str(DATASET_CONFIG),\n",
    "    **training_params\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "training_duration = end_time - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENTRENAMIENTO COMPLETADO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Fin: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Duración total: {training_duration}\")\n",
    "print(f\"\\nModelo guardado en: {results.save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar modelo en el conjunto de validación\n",
    "print(\"\\nEvaluando modelo en conjunto de validación...\")\n",
    "metrics = model.val()\n",
    "\n",
    "print(\"\\nMÉTRICAS DE VALIDACIÓN:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Box mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"Box mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Mask mAP50: {metrics.seg.map50:.4f}\")\n",
    "print(f\"Mask mAP50-95: {metrics.seg.map:.4f}\")\n",
    "print(f\"\\nPrecision (Box): {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall (Box): {metrics.box.mr:.4f}\")\n",
    "print(f\"Precision (Mask): {metrics.seg.mp:.4f}\")\n",
    "print(f\"Recall (Mask): {metrics.seg.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar métricas finales\n",
    "final_metrics = {\n",
    "    'training_duration': str(training_duration),\n",
    "    'final_epoch': results.epoch,\n",
    "    'box_map50': float(metrics.box.map50),\n",
    "    'box_map50_95': float(metrics.box.map),\n",
    "    'mask_map50': float(metrics.seg.map50),\n",
    "    'mask_map50_95': float(metrics.seg.map),\n",
    "    'box_precision': float(metrics.box.mp),\n",
    "    'box_recall': float(metrics.box.mr),\n",
    "    'mask_precision': float(metrics.seg.mp),\n",
    "    'mask_recall': float(metrics.seg.mr),\n",
    "    'training_config': training_params,\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "metrics_file = Path(results.save_dir) / 'final_metrics.json'\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(final_metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\nMétricas guardadas en: {metrics_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de Resultados de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar resultados de entrenamiento\n",
    "results_csv = Path(results.save_dir) / 'results.csv'\n",
    "if results_csv.exists():\n",
    "    df_results = pd.read_csv(results_csv)\n",
    "    df_results.columns = df_results.columns.str.strip()\n",
    "    \n",
    "    print(\"Columnas disponibles en results.csv:\")\n",
    "    print(df_results.columns.tolist())\n",
    "    \n",
    "    # Gráficas de métricas de entrenamiento\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # mAP50 y mAP50-95\n",
    "    axes[0, 0].plot(df_results['epoch'], df_results['metrics/mAP50(B)'], label='Box mAP50', linewidth=2)\n",
    "    axes[0, 0].plot(df_results['epoch'], df_results['metrics/mAP50-95(B)'], label='Box mAP50-95', linewidth=2)\n",
    "    axes[0, 0].plot(df_results['epoch'], df_results['metrics/mAP50(M)'], label='Mask mAP50', linewidth=2, linestyle='--')\n",
    "    axes[0, 0].plot(df_results['epoch'], df_results['metrics/mAP50-95(M)'], label='Mask mAP50-95', linewidth=2, linestyle='--')\n",
    "    axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('mAP', fontsize=12)\n",
    "    axes[0, 0].set_title('Mean Average Precision', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Precision y Recall\n",
    "    axes[0, 1].plot(df_results['epoch'], df_results['metrics/precision(B)'], label='Box Precision', linewidth=2)\n",
    "    axes[0, 1].plot(df_results['epoch'], df_results['metrics/recall(B)'], label='Box Recall', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Score', fontsize=12)\n",
    "    axes[0, 1].set_title('Precision & Recall', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Losses\n",
    "    loss_cols = [col for col in df_results.columns if 'loss' in col.lower() and 'train' in col.lower()]\n",
    "    for col in loss_cols:\n",
    "        axes[1, 0].plot(df_results['epoch'], df_results[col], label=col.replace('train/', ''), linewidth=2)\n",
    "    axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1, 0].set_title('Training Losses', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate\n",
    "    if 'lr/pg0' in df_results.columns:\n",
    "        axes[1, 1].plot(df_results['epoch'], df_results['lr/pg0'], linewidth=2, color='red')\n",
    "        axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "        axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n",
    "        axes[1, 1].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(results.save_dir) / 'training_metrics.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No se encontró archivo results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportar Modelo para Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar a diferentes formatos\n",
    "export_dir = MODELS_DIR / 'exports'\n",
    "export_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Exportando modelo a diferentes formatos...\\n\")\n",
    "\n",
    "# Copiar el mejor modelo a directorio de exportación\n",
    "best_model_path = Path(results.save_dir) / 'weights' / 'best.pt'\n",
    "final_model_path = export_dir / 'yolo11x_pothole_best.pt'\n",
    "\n",
    "import shutil\n",
    "if best_model_path.exists():\n",
    "    shutil.copy(best_model_path, final_model_path)\n",
    "    print(f\"✓ Modelo PyTorch guardado: {final_model_path}\")\n",
    "\n",
    "# Cargar el mejor modelo para exportación\n",
    "best_model = YOLO(str(best_model_path))\n",
    "\n",
    "# Exportar a ONNX (para compatibilidad multiplataforma)\n",
    "try:\n",
    "    onnx_path = best_model.export(format='onnx', dynamic=True, simplify=True)\n",
    "    print(f\"✓ Modelo ONNX exportado: {onnx_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error exportando ONNX: {e}\")\n",
    "\n",
    "# Exportar a TorchScript (para producción PyTorch)\n",
    "try:\n",
    "    torchscript_path = best_model.export(format='torchscript')\n",
    "    print(f\"✓ Modelo TorchScript exportado: {torchscript_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error exportando TorchScript: {e}\")\n",
    "\n",
    "print(f\"\\nTodos los modelos exportados a: {export_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas de Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo final para pruebas\n",
    "final_model = YOLO(str(final_model_path))\n",
    "\n",
    "print(\"Modelo cargado y listo para inferencia!\")\n",
    "print(f\"\\nPara usar el modelo en inferencia:\")\n",
    "print(f\"  model = YOLO('{final_model_path}')\")\n",
    "print(f\"  results = model.predict(source='image.jpg', conf=0.25, iou=0.7)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de prueba de inferencia en imágenes del conjunto de validación\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Buscar imágenes de validación\n",
    "valid_images_dir = Path('../dataset/valid/images')\n",
    "if valid_images_dir.exists():\n",
    "    valid_images = list(valid_images_dir.glob('*.png')) + list(valid_images_dir.glob('*.jpg'))\n",
    "    \n",
    "    if len(valid_images) > 0:\n",
    "        # Seleccionar 5 imágenes aleatorias\n",
    "        sample_images = random.sample(valid_images, min(5, len(valid_images)))\n",
    "        \n",
    "        print(f\"Ejecutando inferencia en {len(sample_images)} imágenes de muestra...\\n\")\n",
    "        \n",
    "        # Ejecutar predicciones\n",
    "        results = final_model.predict(\n",
    "            source=sample_images,\n",
    "            conf=0.25,\n",
    "            iou=0.7,\n",
    "            save=True,\n",
    "            project=str(MODELS_DIR / 'inference_samples'),\n",
    "            name='validation_samples',\n",
    "            exist_ok=True\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nResultados de inferencia guardados en: {MODELS_DIR / 'inference_samples' / 'validation_samples'}\")\n",
    "        \n",
    "        # Mostrar estadísticas\n",
    "        total_detections = sum([len(r.boxes) for r in results])\n",
    "        print(f\"\\nEstadísticas:\")\n",
    "        print(f\"  Total de imágenes: {len(sample_images)}\")\n",
    "        print(f\"  Total de baches detectados: {total_detections}\")\n",
    "        print(f\"  Promedio de baches por imagen: {total_detections/len(sample_images):.2f}\")\n",
    "    else:\n",
    "        print(\"No se encontraron imágenes en el directorio de validación.\")\n",
    "else:\n",
    "    print(f\"Directorio de validación no encontrado: {valid_images_dir}\")\n",
    "    print(\"Por favor, actualiza la ruta del dataset en el notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN DE ENTRENAMIENTO FINAL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nModelo: YOLOv11x-seg\")\n",
    "print(f\"Duración de entrenamiento: {training_duration}\")\n",
    "print(f\"Epochs completados: {results.epoch}\")\n",
    "print(f\"\\nMétricas Finales:\")\n",
    "print(f\"  Box mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"  Mask mAP50-95: {metrics.seg.map:.4f}\")\n",
    "print(f\"  Precision (Mask): {metrics.seg.mp:.4f}\")\n",
    "print(f\"  Recall (Mask): {metrics.seg.mr:.4f}\")\n",
    "print(f\"\\nModelo final guardado en:\")\n",
    "print(f\"  PyTorch: {final_model_path}\")\n",
    "print(f\"  Directorio de exportación: {export_dir}\")\n",
    "print(f\"\\nArchivos generados:\")\n",
    "print(f\"  Métricas: {metrics_file}\")\n",
    "print(f\"  Resultados: {results.save_dir}\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"¡Entrenamiento completado exitosamente!\")\n",
    "print(\"Siguiente paso: Clasificación según norma ASTM D6433-03\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
