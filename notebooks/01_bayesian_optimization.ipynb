{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización Bayesiana de Hiperparámetros - YOLOv11 Pothole Detection\n",
    "\n",
    "Este notebook utiliza Optuna para realizar optimización bayesiana y encontrar los mejores hiperparámetros para entrenar YOLOv11 en la detección de baches.\n",
    "\n",
    "## Hardware: RTX 5090 (32GB VRAM)\n",
    "## Task: Instance Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuración de estilo\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar GPU disponible\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM Total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"VRAM Available: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de rutas\n",
    "BASE_DIR = Path('..')\n",
    "CONFIG_DIR = BASE_DIR / 'config'\n",
    "DATASET_CONFIG = CONFIG_DIR / 'pothole_dataset.yaml'\n",
    "MODELS_DIR = BASE_DIR / 'models'\n",
    "OPTIMIZATION_DIR = MODELS_DIR / 'optimization'\n",
    "OPTIMIZATION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset Config: {DATASET_CONFIG}\")\n",
    "print(f\"Models Directory: {MODELS_DIR}\")\n",
    "print(f\"Optimization Directory: {OPTIMIZATION_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de la optimización\n",
    "OPTIMIZATION_CONFIG = {\n",
    "    'n_trials': 50,  # Número de trials para la optimización bayesiana\n",
    "    'n_epochs_per_trial': 30,  # Epochs por trial (reducido para optimización)\n",
    "    'imgsz': 640,  # Tamaño de imagen base\n",
    "    'model_variant': 'yolo11n-seg.pt',  # Usar nano para optimización rápida\n",
    "    'device': 0,  # GPU 0\n",
    "    'workers': 8,  # Workers para dataloader\n",
    "    'patience': 10,  # Early stopping patience\n",
    "}\n",
    "\n",
    "print(\"Configuración de optimización:\")\n",
    "for key, value in OPTIMIZATION_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la Función Objetivo\n",
    "\n",
    "Esta función será optimizada por Optuna. Retorna la métrica mAP50-95 (box) como objetivo a maximizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Función objetivo para Optuna.\n",
    "    \n",
    "    Hiperparámetros a optimizar:\n",
    "    - Learning rate inicial (lr0)\n",
    "    - Learning rate final (lrf)\n",
    "    - Momentum\n",
    "    - Weight decay\n",
    "    - Warmup epochs\n",
    "    - Batch size\n",
    "    - Image size\n",
    "    - Mosaic augmentation\n",
    "    - Mixup augmentation\n",
    "    - HSV augmentations (Hue, Saturation, Value)\n",
    "    - Flip augmentation probability\n",
    "    - Scale augmentation\n",
    "    - Translate augmentation\n",
    "    - Box loss gain\n",
    "    - Cls loss gain\n",
    "    - DFL loss gain\n",
    "    \"\"\"\n",
    "    \n",
    "    # Hiperparámetros de optimización\n",
    "    lr0 = trial.suggest_float('lr0', 1e-5, 1e-2, log=True)\n",
    "    lrf = trial.suggest_float('lrf', 0.01, 0.2)\n",
    "    momentum = trial.suggest_float('momentum', 0.8, 0.99)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    warmup_epochs = trial.suggest_int('warmup_epochs', 1, 5)\n",
    "    \n",
    "    # Batch size y image size (aprovechando la RTX 5090)\n",
    "    batch_size = trial.suggest_categorical('batch', [16, 24, 32, 40])\n",
    "    imgsz = trial.suggest_categorical('imgsz', [640, 768, 896])\n",
    "    \n",
    "    # Data augmentation\n",
    "    mosaic = trial.suggest_float('mosaic', 0.5, 1.0)\n",
    "    mixup = trial.suggest_float('mixup', 0.0, 0.3)\n",
    "    hsv_h = trial.suggest_float('hsv_h', 0.0, 0.1)\n",
    "    hsv_s = trial.suggest_float('hsv_s', 0.0, 0.9)\n",
    "    hsv_v = trial.suggest_float('hsv_v', 0.0, 0.9)\n",
    "    flipud = trial.suggest_float('flipud', 0.0, 0.5)\n",
    "    fliplr = trial.suggest_float('fliplr', 0.3, 0.7)\n",
    "    scale = trial.suggest_float('scale', 0.3, 0.7)\n",
    "    translate = trial.suggest_float('translate', 0.05, 0.2)\n",
    "    \n",
    "    # Loss gains\n",
    "    box_gain = trial.suggest_float('box', 5.0, 10.0)\n",
    "    cls_gain = trial.suggest_float('cls', 0.3, 1.0)\n",
    "    dfl_gain = trial.suggest_float('dfl', 1.0, 2.5)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = trial.suggest_categorical('optimizer', ['SGD', 'Adam', 'AdamW'])\n",
    "    \n",
    "    # Nombre del trial\n",
    "    trial_name = f\"trial_{trial.number:03d}\"\n",
    "    trial_dir = OPTIMIZATION_DIR / trial_name\n",
    "    \n",
    "    try:\n",
    "        # Cargar modelo\n",
    "        model = YOLO(OPTIMIZATION_CONFIG['model_variant'])\n",
    "        \n",
    "        # Entrenar con los hiperparámetros sugeridos\n",
    "        results = model.train(\n",
    "            data=str(DATASET_CONFIG),\n",
    "            epochs=OPTIMIZATION_CONFIG['n_epochs_per_trial'],\n",
    "            imgsz=imgsz,\n",
    "            batch=batch_size,\n",
    "            device=OPTIMIZATION_CONFIG['device'],\n",
    "            workers=OPTIMIZATION_CONFIG['workers'],\n",
    "            patience=OPTIMIZATION_CONFIG['patience'],\n",
    "            project=str(OPTIMIZATION_DIR),\n",
    "            name=trial_name,\n",
    "            exist_ok=True,\n",
    "            pretrained=True,\n",
    "            \n",
    "            # Hiperparámetros optimizados\n",
    "            lr0=lr0,\n",
    "            lrf=lrf,\n",
    "            momentum=momentum,\n",
    "            weight_decay=weight_decay,\n",
    "            warmup_epochs=warmup_epochs,\n",
    "            optimizer=optimizer,\n",
    "            \n",
    "            # Augmentations\n",
    "            mosaic=mosaic,\n",
    "            mixup=mixup,\n",
    "            hsv_h=hsv_h,\n",
    "            hsv_s=hsv_s,\n",
    "            hsv_v=hsv_v,\n",
    "            flipud=flipud,\n",
    "            fliplr=fliplr,\n",
    "            scale=scale,\n",
    "            translate=translate,\n",
    "            \n",
    "            # Loss gains\n",
    "            box=box_gain,\n",
    "            cls=cls_gain,\n",
    "            dfl=dfl_gain,\n",
    "            \n",
    "            # Otras configuraciones\n",
    "            verbose=False,\n",
    "            plots=False,\n",
    "            save=True,\n",
    "            save_period=-1,  # Solo guardar el mejor modelo\n",
    "        )\n",
    "        \n",
    "        # Obtener métricas de validación\n",
    "        # Para segmentación, usamos metrics/mAP50-95(M) que es la métrica de máscara\n",
    "        map_score = results.results_dict.get('metrics/mAP50-95(M)', 0.0)\n",
    "        \n",
    "        # Guardar información del trial\n",
    "        trial_info = {\n",
    "            'trial_number': trial.number,\n",
    "            'mAP50-95': map_score,\n",
    "            'hyperparameters': trial.params,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(trial_dir / 'trial_info.json', 'w') as f:\n",
    "            json.dump(trial_info, f, indent=2)\n",
    "        \n",
    "        # Limpiar memoria\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return map_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error en trial {trial.number}: {str(e)}\")\n",
    "        # Limpiar memoria en caso de error\n",
    "        torch.cuda.empty_cache()\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutar Optimización Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear estudio de Optuna\n",
    "study_name = f\"yolo11_pothole_optimization_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "storage_name = f\"sqlite:///{OPTIMIZATION_DIR}/{study_name}.db\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    direction='maximize',  # Maximizar mAP\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),  # Tree-structured Parzen Estimator\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    ")\n",
    "\n",
    "print(f\"Estudio creado: {study_name}\")\n",
    "print(f\"Storage: {storage_name}\")\n",
    "print(f\"\\nIniciando optimización bayesiana con {OPTIMIZATION_CONFIG['n_trials']} trials...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar optimización\n",
    "study.optimize(\n",
    "    objective, \n",
    "    n_trials=OPTIMIZATION_CONFIG['n_trials'],\n",
    "    show_progress_bar=True,\n",
    "    n_jobs=1  # Usar 1 job debido al uso de GPU\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OPTIMIZACIÓN COMPLETADA\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejores hiperparámetros\n",
    "print(\"\\nMEJORES HIPERPARÁMETROS ENCONTRADOS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Mejor mAP50-95: {study.best_value:.4f}\")\n",
    "print(f\"\\nHiperparámetros:\")\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Guardar mejores hiperparámetros\n",
    "best_params_file = OPTIMIZATION_DIR / 'best_hyperparameters.json'\n",
    "with open(best_params_file, 'w') as f:\n",
    "    json.dump({\n",
    "        'best_value': study.best_value,\n",
    "        'best_params': study.best_params,\n",
    "        'best_trial': study.best_trial.number,\n",
    "        'study_name': study_name,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\nMejores hiperparámetros guardados en: {best_params_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir trials a DataFrame para análisis\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_df.to_csv(OPTIMIZATION_DIR / 'optimization_trials.csv', index=False)\n",
    "\n",
    "print(f\"Total de trials completados: {len(trials_df)}\")\n",
    "print(f\"\\nEstadísticas de mAP50-95:\")\n",
    "print(trials_df['value'].describe())\n",
    "\n",
    "# Mostrar top 10 trials\n",
    "print(\"\\nTop 10 Trials:\")\n",
    "top_trials = trials_df.nlargest(10, 'value')[['number', 'value']]\n",
    "print(top_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historia de optimización\n",
    "fig1 = plot_optimization_history(study)\n",
    "fig1.update_layout(\n",
    "    title='Historia de Optimización Bayesiana',\n",
    "    xaxis_title='Trial',\n",
    "    yaxis_title='mAP50-95 (Mask)',\n",
    "    width=1200,\n",
    "    height=600\n",
    ")\n",
    "fig1.write_html(OPTIMIZATION_DIR / 'optimization_history.html')\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de hiperparámetros\n",
    "fig2 = plot_param_importances(study)\n",
    "fig2.update_layout(\n",
    "    title='Importancia de Hiperparámetros',\n",
    "    width=1200,\n",
    "    height=800\n",
    ")\n",
    "fig2.write_html(OPTIMIZATION_DIR / 'param_importances.html')\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de valores por hiperparámetro\n",
    "from optuna.visualization import plot_slice\n",
    "\n",
    "fig3 = plot_slice(study)\n",
    "fig3.update_layout(\n",
    "    title='Distribución de Hiperparámetros vs mAP',\n",
    "    width=1400,\n",
    "    height=1000\n",
    ")\n",
    "fig3.write_html(OPTIMIZATION_DIR / 'param_slices.html')\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel coordinate plot\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "\n",
    "fig4 = plot_parallel_coordinate(study)\n",
    "fig4.update_layout(\n",
    "    title='Parallel Coordinate Plot',\n",
    "    width=1400,\n",
    "    height=800\n",
    ")\n",
    "fig4.write_html(OPTIMIZATION_DIR / 'parallel_coordinate.html')\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación entre hiperparámetros\n",
    "plt.figure(figsize=(16, 14))\n",
    "\n",
    "# Seleccionar columnas numéricas de parámetros\n",
    "param_cols = [col for col in trials_df.columns if col.startswith('params_')]\n",
    "correlation_data = trials_df[param_cols + ['value']].copy()\n",
    "\n",
    "# Renombrar columnas para mejor visualización\n",
    "correlation_data.columns = [col.replace('params_', '') for col in correlation_data.columns]\n",
    "\n",
    "# Calcular correlación\n",
    "correlation_matrix = correlation_data.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(\n",
    "    correlation_matrix, \n",
    "    annot=True, \n",
    "    fmt='.2f', \n",
    "    cmap='coolwarm', \n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=1\n",
    ")\n",
    "plt.title('Correlación entre Hiperparámetros y mAP', fontsize=16, pad=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OPTIMIZATION_DIR / 'correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear Archivo de Configuración para Entrenamiento Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear configuración YAML con los mejores hiperparámetros\n",
    "training_config = {\n",
    "    'model': 'yolo11x-seg.pt',  # Usar el modelo más grande para entrenamiento final\n",
    "    'data': str(DATASET_CONFIG),\n",
    "    'epochs': 300,  # Más epochs para entrenamiento final\n",
    "    'patience': 50,\n",
    "    'device': 0,\n",
    "    'workers': 8,\n",
    "    'project': '../models/final_training',\n",
    "    'name': 'yolo11x_pothole_best',\n",
    "    \n",
    "    # Mejores hiperparámetros encontrados\n",
    "    **study.best_params\n",
    "}\n",
    "\n",
    "# Guardar configuración\n",
    "training_config_file = CONFIG_DIR / 'training_config.yaml'\n",
    "with open(training_config_file, 'w') as f:\n",
    "    yaml.dump(training_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"Configuración de entrenamiento guardada en: {training_config_file}\")\n",
    "print(\"\\nContenido:\")\n",
    "print(yaml.dump(training_config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN DE OPTIMIZACIÓN BAYESIANA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal de trials ejecutados: {len(study.trials)}\")\n",
    "print(f\"Mejor mAP50-95 alcanzado: {study.best_value:.4f}\")\n",
    "print(f\"Trial con mejor resultado: {study.best_trial.number}\")\n",
    "print(f\"\\nArchivos generados:\")\n",
    "print(f\"  - Mejores hiperparámetros: {best_params_file}\")\n",
    "print(f\"  - Configuración de entrenamiento: {training_config_file}\")\n",
    "print(f\"  - Base de datos de trials: {storage_name}\")\n",
    "print(f\"  - CSV de trials: {OPTIMIZATION_DIR / 'optimization_trials.csv'}\")\n",
    "print(f\"  - Visualizaciones: {OPTIMIZATION_DIR}/*.html\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"¡Optimización completada! Procede al notebook de entrenamiento final.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
