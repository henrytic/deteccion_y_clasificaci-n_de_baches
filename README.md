# ğŸ›£ï¸ Sistema de DetecciÃ³n y ClasificaciÃ³n de Baches

Sistema completo de detecciÃ³n y clasificaciÃ³n de baches usando **YOLOv11** con segmentaciÃ³n de instancias y clasificaciÃ³n segÃºn la norma **ASTM D6433-03**.

## ğŸ“‹ CaracterÃ­sticas

- âœ… **DetecciÃ³n con YOLOv11**: SegmentaciÃ³n de instancias para detecciÃ³n precisa de baches
- âœ… **ClasificaciÃ³n ASTM D6433-03**: ClasificaciÃ³n automÃ¡tica segÃºn severidad (Low, Medium, High)
- âœ… **OptimizaciÃ³n Bayesiana**: BÃºsqueda automÃ¡tica de mejores hiperparÃ¡metros con Optuna
- âœ… **Procesamiento de Video**: AnÃ¡lisis completo de videos con detecciÃ³n frame por frame
- âœ… **Mapas de Calor**: VisualizaciÃ³n de densidad y severidad de baches
- âœ… **AplicaciÃ³n Web**: Interface web interactiva con Streamlit
- âœ… **Reportes AutomÃ¡ticos**: GeneraciÃ³n de reportes en JSON y PDF
- âœ… **Hardware Optimizado**: Optimizado para RTX 5090 (32GB VRAM)

## ğŸ—ï¸ Estructura del Proyecto

```
.
â”œâ”€â”€ config/                          # Configuraciones
â”‚   â”œâ”€â”€ pothole_dataset.yaml        # ConfiguraciÃ³n del dataset YOLO
â”‚   â””â”€â”€ training_config.yaml        # ConfiguraciÃ³n de entrenamiento (generado)
â”‚
â”œâ”€â”€ dataset/                         # Dataset (crear esta carpeta)
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ images/                 # ImÃ¡genes de entrenamiento (.png)
â”‚   â”‚   â””â”€â”€ labels/                 # Etiquetas YOLO (.txt con polÃ­gonos)
â”‚   â””â”€â”€ valid/
â”‚       â”œâ”€â”€ images/                 # ImÃ¡genes de validaciÃ³n
â”‚       â””â”€â”€ labels/                 # Etiquetas de validaciÃ³n
â”‚
â”œâ”€â”€ models/                          # Modelos entrenados
â”‚   â”œâ”€â”€ optimization/               # Resultados de optimizaciÃ³n bayesiana
â”‚   â”œâ”€â”€ final_training/             # Modelo final entrenado
â”‚   â””â”€â”€ exports/                    # Modelos exportados (.pt, .onnx, etc.)
â”‚
â”œâ”€â”€ notebooks/                       # Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_bayesian_optimization.ipynb  # OptimizaciÃ³n de hiperparÃ¡metros
â”‚   â””â”€â”€ 02_final_training.ipynb         # Entrenamiento final
â”‚
â”œâ”€â”€ scripts/                         # Scripts de utilidad
â”‚   â””â”€â”€ process_video.py            # Procesamiento de videos por lotes
â”‚
â”œâ”€â”€ utils/                           # MÃ³dulos de utilidades
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ astm_classifier.py          # Clasificador segÃºn ASTM D6433-03
â”‚   â””â”€â”€ visualizations.py           # Funciones de visualizaciÃ³n
â”‚
â”œâ”€â”€ webapp/                          # AplicaciÃ³n web
â”‚   â””â”€â”€ app.py                      # AplicaciÃ³n Streamlit
â”‚
â”œâ”€â”€ requirements.txt                 # Dependencias Python
â””â”€â”€ README.md                        # Este archivo
```

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone <url-del-repositorio>
cd deteccion_y_clasificaci-n_de_baches
```

### 2. Crear entorno virtual (recomendado)

```bash
python -m venv venv
source venv/bin/activate  # En Linux/Mac
# o
venv\Scripts\activate  # En Windows
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Verificar instalaciÃ³n de PyTorch con CUDA

```bash
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
python -c "import torch; print(f'GPU: {torch.cuda.get_device_name(0)}')"
```

## ğŸ“Š PreparaciÃ³n del Dataset

### Estructura del Dataset

Crea la carpeta `dataset/` con la siguiente estructura:

```
dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/     # Archivos .png o .jpg
â”‚   â””â”€â”€ labels/     # Archivos .txt (mismo nombre que las imÃ¡genes)
â””â”€â”€ valid/
    â”œâ”€â”€ images/
    â””â”€â”€ labels/
```

### Formato de Etiquetas

Las etiquetas deben estar en formato **YOLO SegmentaciÃ³n de Instancias**:

```
<class_id> <x1> <y1> <x2> <y2> ... <xn> <yn>
```

- `class_id`: Siempre 0 (solo una clase: bache)
- `x1 y1 ... xn yn`: Coordenadas normalizadas (0-1) del polÃ­gono

**Ejemplo:**
```
0 0.514032 0.660228 0.457314 0.635170 0.450803 0.628660 ...
```

### Actualizar ConfiguraciÃ³n

Edita `config/pothole_dataset.yaml` si tu dataset estÃ¡ en otra ubicaciÃ³n:

```yaml
path: ./dataset  # Ruta al dataset
train: train/images
val: valid/images
```

## ğŸ”§ Uso

### Paso 1: OptimizaciÃ³n de HiperparÃ¡metros

Ejecuta el notebook de optimizaciÃ³n bayesiana para encontrar los mejores hiperparÃ¡metros:

```bash
jupyter notebook notebooks/01_bayesian_optimization.ipynb
```

Este proceso:
- Ejecuta 50 trials de optimizaciÃ³n bayesiana con Optuna
- Prueba diferentes combinaciones de hiperparÃ¡metros
- Guarda los mejores resultados en `models/optimization/best_hyperparameters.json`
- Genera visualizaciones de la optimizaciÃ³n

**DuraciÃ³n estimada**: 8-12 horas (dependiendo del tamaÃ±o del dataset)

### Paso 2: Entrenamiento Final

Una vez completada la optimizaciÃ³n, ejecuta el entrenamiento final:

```bash
jupyter notebook notebooks/02_final_training.ipynb
```

Este proceso:
- Carga los mejores hiperparÃ¡metros encontrados
- Entrena el modelo YOLOv11x-seg completo (300 epochs)
- Guarda el modelo en `models/final_training/`
- Exporta el modelo a diferentes formatos (.pt, .onnx, .torchscript)

**DuraciÃ³n estimada**: 24-48 horas (dependiendo del dataset)

### Paso 3: Procesamiento de Videos

#### OpciÃ³n A: AplicaciÃ³n Web (Recomendado)

Lanza la aplicaciÃ³n web interactiva:

```bash
streamlit run webapp/app.py
```

La aplicaciÃ³n te permite:
- Cargar videos directamente desde el navegador
- Ver el procesamiento en tiempo real
- Explorar mapas de calor y estadÃ­sticas
- Generar reportes PDF y JSON
- Descargar resultados

#### OpciÃ³n B: LÃ­nea de Comandos

Procesa videos desde la terminal:

```bash
python scripts/process_video.py path/to/video.mp4 \
    --model models/exports/yolo11x_pothole_best.pt \
    --output output/ \
    --conf 0.25 \
    --iou 0.7 \
    --pixels-per-mm 2.0
```

**ParÃ¡metros:**
- `input`: Video o directorio con videos
- `--model`: Ruta al modelo entrenado
- `--output`: Directorio de salida
- `--conf`: Umbral de confianza (default: 0.25)
- `--iou`: Umbral de IoU para NMS (default: 0.7)
- `--pixels-per-mm`: Factor de calibraciÃ³n (default: 1.0)
- `--no-video`: No guardar video procesado
- `--save-frames`: Guardar frames individuales
- `--frame-interval`: Intervalo de frames a guardar

**Ejemplo con mÃºltiples videos:**

```bash
python scripts/process_video.py videos/ \
    --model models/exports/yolo11x_pothole_best.pt \
    --output results/ \
    --save-frames \
    --frame-interval 30
```

## ğŸ“ ClasificaciÃ³n segÃºn ASTM D6433-03

El sistema clasifica los baches segÃºn la norma **ASTM D6433-03** basÃ¡ndose en el diÃ¡metro:

| Severidad | Criterio (DiÃ¡metro) | Color | Score |
|-----------|-------------------|-------|-------|
| **Low (L)** | < 200 mm | ğŸŸ¢ Verde | 0-33 |
| **Medium (M)** | 200-450 mm | ğŸŸ  Naranja | 34-66 |
| **High (H)** | > 450 mm | ğŸ”´ Rojo | 67-100 |

### CalibraciÃ³n

Para obtener mediciones precisas en mm, calibra el factor `pixels_per_mm`:

```python
from utils import estimate_pixels_per_mm

# Ejemplo: CÃ¡mara a 3m de altura, FOV 60Â°
pixels_per_mm = estimate_pixels_per_mm(
    image_height_px=1080,
    camera_height_m=3.0,
    camera_fov_degrees=60.0
)

print(f"PÃ­xeles por mm: {pixels_per_mm}")
```

## ğŸ“Š Reportes Generados

### 1. Reporte JSON

Contiene:
- Metadata del video
- EstadÃ­sticas de detecciÃ³n
- Lista completa de detecciones con coordenadas y clasificaciÃ³n
- InformaciÃ³n de calibraciÃ³n

### 2. Reporte PDF

Incluye:
- InformaciÃ³n general del anÃ¡lisis
- DistribuciÃ³n por severidad
- EstadÃ­sticas de diÃ¡metros
- Cumplimiento con ASTM D6433-03

### 3. Visualizaciones

- **Mapa de calor**: Densidad y severidad de baches
- **Histogramas**: DistribuciÃ³n de diÃ¡metros
- **GrÃ¡ficas de pastel**: DistribuciÃ³n por severidad
- **Video procesado**: Video con anotaciones

## ğŸ¯ OptimizaciÃ³n con RTX 5090

El sistema estÃ¡ optimizado para aprovechar la RTX 5090:

### ConfiguraciÃ³n Recomendada

```python
# OptimizaciÃ³n Bayesiana (rÃ¡pida)
batch_size = 32-40
imgsz = 640-896
model = 'yolo11n-seg.pt'  # Nano para optimizaciÃ³n

# Entrenamiento Final (mÃ¡xima calidad)
batch_size = 24-32
imgsz = 896-1024
model = 'yolo11x-seg.pt'  # Extra-large para mejor accuracy
amp = True  # Automatic Mixed Precision
```

### Monitorear Uso de GPU

```python
import torch

print(f"VRAM Asignada: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB")
print(f"VRAM Reservada: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB")
```

## ğŸ”¬ Mejoras y PersonalizaciÃ³n

### Agregar Nuevas Clases

Si quieres detectar mÃºltiples tipos de daÃ±os, modifica `config/pothole_dataset.yaml`:

```yaml
nc: 3  # NÃºmero de clases
names:
  0: pothole
  1: crack
  2: patch
```

### Personalizar Umbrales ASTM

Modifica los umbrales en `utils/astm_classifier.py`:

```python
classifier = ASTMPotholeClassifier(
    pixels_per_mm=2.0,
    low_threshold_mm=150,   # Personalizado
    high_threshold_mm=400   # Personalizado
)
```

### Fine-tuning

Para continuar el entrenamiento desde un checkpoint:

```python
model = YOLO('models/final_training/yolo11x_pothole_final/weights/best.pt')
model.train(resume=True)
```

## ğŸ“ Ejemplos de Uso

### Ejemplo 1: DetecciÃ³n en Imagen

```python
from ultralytics import YOLO
from utils import ASTMPotholeClassifier, draw_detections_on_frame
import cv2

# Cargar modelo
model = YOLO('models/exports/yolo11x_pothole_best.pt')

# Cargar clasificador
classifier = ASTMPotholeClassifier(pixels_per_mm=2.0)

# Procesar imagen
image = cv2.imread('road.jpg')
results = model.predict(image, conf=0.25)

# Clasificar
potholes = classifier.process_yolo_results(results)

# Dibujar
annotated = draw_detections_on_frame(image, potholes)
cv2.imwrite('output.jpg', annotated)

# Ver estadÃ­sticas
for p in potholes:
    print(f"Bache {p.id}: {p.diameter_mm:.1f}mm - {p.severity.value}")
```

### Ejemplo 2: Mapa de Calor

```python
from utils import create_heatmap, apply_heatmap_colormap
import cv2

# Crear mapa de calor
heatmap = create_heatmap(
    image_shape=image.shape[:2],
    potholes=potholes,
    sigma=50.0,
    use_severity=True
)

# Aplicar colores
heatmap_colored = apply_heatmap_colormap(heatmap, cv2.COLORMAP_JET)

# Guardar
cv2.imwrite('heatmap.jpg', heatmap_colored)
```

### Ejemplo 3: EstadÃ­sticas

```python
from utils import generate_summary_statistics

stats = generate_summary_statistics(potholes)

print(f"Total: {stats['total_potholes']}")
print(f"Low: {stats['severity_distribution']['Low']}")
print(f"Medium: {stats['severity_distribution']['Medium']}")
print(f"High: {stats['severity_distribution']['High']}")
print(f"DiÃ¡metro promedio: {stats['average_diameter_mm']:.1f} mm")
```

## ğŸ› SoluciÃ³n de Problemas

### Error: CUDA out of memory

Reduce el tamaÃ±o del batch o la resoluciÃ³n de imagen:

```python
batch_size = 16  # Reducir
imgsz = 640      # Reducir
```

### Error: Model not found

Verifica la ruta del modelo:

```bash
ls -la models/exports/yolo11x_pothole_best.pt
```

### Detecciones de baja calidad

- Aumenta el tiempo de entrenamiento (mÃ¡s epochs)
- Verifica la calidad de las etiquetas del dataset
- Ajusta el umbral de confianza
- Calibra `pixels_per_mm` correctamente

### Video procesado no se guarda

Verifica que tienes los codecs necesarios:

```bash
pip install opencv-python-headless
```

## ğŸ“š Referencias

- **YOLOv11**: [Ultralytics Documentation](https://docs.ultralytics.com/)
- **ASTM D6433-03**: Standard Practice for Roads and Parking Lots Pavement Condition Index Surveys
- **Optuna**: [Optuna Documentation](https://optuna.readthedocs.io/)

## ğŸ“„ Licencia

Ver archivo `LICENSE`

## ğŸ‘¥ Contribuciones

Las contribuciones son bienvenidas! Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“§ Contacto

Para preguntas o sugerencias, por favor abre un issue en el repositorio.

---

**Desarrollado con â¤ï¸ usando YOLOv11 y Python**
